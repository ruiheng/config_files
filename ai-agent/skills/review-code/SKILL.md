---
name: review-code
description: Reviews code changes for logical correctness, design quality, and security. Use after code has been written to validate implementation quality.
---

# Review Code

Review code changes for logical correctness, design quality, and security.

## Input

Provide one of the following:
1. A `review-request-*.md` file (generated by the implementer after task completion), OR
2. The original task description + implementation summary + code changes

## Input Completeness Gate (Required)

Before reviewing code quality, verify the input includes enough context:
- Scope is explicit (uncommitted / commit / branch and target)
- Review focus or risk angles are stated (for example: compatibility, security boundaries, data migration, performance regression)
- Verification evidence is present (tests run, results, and known coverage gaps)

If critical context is missing, mark the review as `NEEDS_REVISION` and list missing items in `Critical Issues`.
Do not fabricate evidence or assumptions.

## What to Review

- **Logic**: Correct implementation of requirements
- **Design**: Appropriate abstractions, minimal coupling
- **Security**: Injection risks, unsafe operations, data leaks
- **Edge Cases**: Boundary condition handling
- **Maintainability**: Code readability, self-documenting where reasonable
- **Compatibility/Regression Risk**: Backward compatibility and unintended behavior changes
- **Verification Coverage**: Whether provided tests/evidence support the claimed behavior

## What NOT to Review

- Syntax validity (linters handle this)
- Style/formatting (formatters handle this)
- Typos in comments/strings

## Output Format

```markdown
### Summary
[APPROVED / NEEDS_REVISION]: Brief rationale (1-2 sentences)

### Request Completeness Check
- Scope clarity: [PASS / FAIL]
- Review focus/risk angles: [PASS / FAIL]
- Verification evidence: [PASS / FAIL]
If any FAIL, explain why in `Critical Issues`.

### Critical Issues
Must fix before merge:
- [ ] **[CATEGORY]**: Description | Suggestion: How to fix
If none, write: `- None.`

### Design Concerns
Architecture/decision questions:
- **[Concern]**: Description | Suggestion: Alternative approach
If none, write: `- None.`

### Minor Suggestions
Optional improvements:
- [ ] Description
If none, write: `- None.`

### Security Check
- Injection risks: [PASS / FAIL / UNKNOWN] - [brief basis]
- Unsafe data exposure: [PASS / FAIL / UNKNOWN] - [brief basis]
- Input validation: [PASS / FAIL / UNKNOWN] - [brief basis]

### Verification Questions
For the implementer/author:
- [Q1] Question
```

## Agent Deck Mode (Context-First)

Enter Agent Deck mode if any is true:
- `task_id` or `planner_session_id` is explicitly provided
- input/report context contains Agent Deck metadata
- user asks for agent-deck flow

`agent-deck session current --json` is best-effort only. Run it in host shell (outside sandbox).
If it fails, continue with explicit/context metadata.

In Agent Deck mode, resolve:
- `task_id`: explicit input -> parse from review-request/report path `.agent-artifacts/<task_id>/...` -> parse from `Agent Deck Context` section -> ask if missing
- `planner_session_id`: explicit input (`planner_session_id`, or `planner_session` as compatibility alias) -> parse from `Agent Deck Context` section -> host-shell detection from `agent-deck session current --json` (`id`) -> ask if missing
- `round`: explicit input -> parse from file suffix `-r<round>.md` -> ask if missing

In Agent Deck mode:
- This skill depends on `agent-deck-workflow` skill script:
  - `scripts/dispatch-control-message.sh` (from the `agent-deck-workflow` skill directory, not this skill directory)
- Required dependency behavior:
  1. ensure `agent-deck-workflow` skill is available/loaded
  2. resolve `agent-deck-workflow` skill directory
  3. invoke `<agent_deck_workflow_skill_dir>/scripts/dispatch-control-message.sh`
  4. if unresolved, stop and ask user to attach/install `agent-deck-workflow` skill

Execution flow in Agent Deck mode:
1. Write the full review report to `.agent-artifacts/<task_id>/review-report-r<round>.md`.
2. Keep the same report content/format quality bar.
3. Select control action:
   - `rework_required` if result is `NEEDS_REVISION`, any must-fix issue exists, or completeness gate has FAIL.
   - `stop_recommended` if no must-fix remains and stop is recommended.
4. For `rework_required`: build JSON control payload and dispatch to executor via helper script (host shell, outside sandbox).
5. For `stop_recommended`: do not dispatch to executor automatically; output user-facing stop recommendation and wait for explicit user decision.

If review result indicates rework needed (for example `NEEDS_REVISION`, critical issues exist, or completeness gate fails):

```json
{
  "schema_version": "1.0",
  "task_id": "<task_id>",
  "planner_session_id": "<planner_session_id>",
  "required_skills": ["agent-deck-workflow"],
  "from_session_id": "<reviewer_session_id>",
  "to_session_id": "<executor_session_id>",
  "round": "<round>",
  "action": "rework_required",
  "artifact_path": ".agent-artifacts/<task_id>/review-report-r<round>.md",
  "note": "Must-fix items remain. Address the review findings and submit the next review request."
}
```

```bash
"<agent_deck_workflow_skill_dir>/scripts/dispatch-control-message.sh" \
  --task-id "<task_id>" \
  --planner-session "<planner_session_id>" \
  --from-session "<reviewer_session_id>" \
  --to-session "<executor_session_id>" \
  --round "<round>" \
  --action "rework_required" \
  --artifact-path ".agent-artifacts/<task_id>/review-report-r<round>.md" \
  --note "Must-fix items remain. Address the review findings and submit the next review request." \
  --no-ensure-session \
  --no-start-session
```

If no must-fix remains and stop is recommended:

```json
{
  "schema_version": "1.0",
  "task_id": "<task_id>",
  "planner_session_id": "<planner_session_id>",
  "required_skills": ["agent-deck-workflow"],
  "from_session_id": "<reviewer_session_id>",
  "to_session_id": "user",
  "round": "<round>",
  "action": "stop_recommended",
  "artifact_path": ".agent-artifacts/<task_id>/review-report-r<round>.md",
  "note": "Stop condition met. User confirmation is required before closeout."
}
```

User-facing output requirement for `stop_recommended`:
- Do not print raw JSON as the primary user-facing content.
- Do not print raw JSON at all unless the user explicitly requests the control payload.
- Provide a concise Markdown summary for the user:
  - review result (`APPROVED` / stop recommended)
  - review report path
  - key residual concerns/questions (if any)
  - verification commands and outcomes
  - explicit decision prompt with two choices:
    1. proceed to `review-closeout` (then notify planner)
    2. continue another implementation iteration (then notify executor)

If user chooses to continue iteration after `stop_recommended`, dispatch to executor:

```bash
"<agent_deck_workflow_skill_dir>/scripts/dispatch-control-message.sh" \
  --task-id "<task_id>" \
  --planner-session "<planner_session_id>" \
  --from-session "<reviewer_session_id>" \
  --to-session "<executor_session_id>" \
  --round "<round>" \
  --action "user_requested_iteration" \
  --artifact-path ".agent-artifacts/<task_id>/review-report-r<round>.md" \
  --note "User requested another implementation iteration. Address the requested follow-ups and submit a new review request." \
  --no-ensure-session \
  --no-start-session
```

Required interaction behavior in Agent Deck mode:
- Do not stop at "printing JSON only".
- For `rework_required`, dispatch automatically after report generation when required metadata is resolved.
- For `stop_recommended`, present user-facing summary and explicit branch choices; do not auto-forward to executor.
- Treat control JSON as internal protocol data; do not print raw JSON in user-facing output unless user explicitly requests the payload.
- Do not ask user ambiguous forwarding questions; ask only the branch decision (`closeout` vs `continue iteration`).
- Report helper output summary only (for example `dispatch_ok ...`).
- After dispatch:
  - for `rework_required`, reviewer waits for executor's next review request.
  - for `stop_recommended`, reviewer waits for explicit user decision.
    - if user confirms closeout: run `review-closeout`
    - if user asks to continue iteration: dispatch `user_requested_iteration` to executor and then wait

## Guidelines

1. Be specific: Reference line numbers or function names
2. Explain why: Describe the problem, not just that something is wrong
3. Suggest fixes: Offer concrete improvements
4. Distinguish severity: Separate blockers from suggestions
5. Assume good intent: Review the code, not the author
6. Stay focused: Review what was asked, not what could be
7. If no critical findings, explicitly state that and mention residual risks/testing gaps
8. Keep output copy/paste friendly: produce a standalone Markdown report with no chat-specific framing
9. Avoid second-person pronouns (`you`, `your`, `你`, `你的`); use neutral references such as `author`, `implementer`, or `submission`
10. Treat missing scope/focus/evidence as review blockers when they prevent reliable judgment
11. Never invent test results, risk assumptions, or implementation details not present in the input
12. In Agent Deck mode, reviewer must proactively dispatch `rework_required` after producing a blocking report; for `stop_recommended`, wait for user decision and branch accordingly
